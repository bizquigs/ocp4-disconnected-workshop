= Preparing the Installation

In this lab, we'll make final preparations and execute the OpenShift Installer.

== Building install-config.yaml

. Let's start by creating a workspace on the bastion to house our installation materials:
+
[source,bash,role=execute,subs="attributes"]
----
mkdir /mnt/high-side-data/install
cd /mnt/high-side-data/install
----

. Then generate an SSH key pair for access to cluster nodes:
+
[source,bash,role=execute,subs="attributes"]
----
ssh-keygen -N ""
----

. Use `jq` to minify your container registry pull secret.
Copy this output to your clipboard, since you'll need it in a moment:
+
[source,bash,role=execute,subs="attributes"]
----
jq -c . /run/user/1000/containers/auth.json
----
+
____
For connected installations, you'd use the secret from the Hybrid Cloud Console, but for our use case, the mirror registry is the only one OpenShift will need to authenticate to.
____

. Then generate `install-config.yaml`:
+
[source,bash,role=execute,subs="attributes"]
----
/mnt/high-side-data/openshift-install create install-config --dir /mnt/high-side-data/install --log-level=DEBUG
----
+
The OpenShift installer will prompt you for a number of fields;
enter the values below:

 ** *SSH Public Key*: `/home/lab-user/.ssh/id_rsa.pub`
+
____
The SSH public key used to access all nodes within the cluster.
____

 ** *Platform*: `aws`
+
____
The platform on which the cluster will run.
____

 ** *AWS Access Key ID* and *Secret Access Key*: Enter your AWS credentials from RHDP.
 ** *Region*: `us-east-1 (US East (N.
Virginia))`
 ** *Base Domain*: `{aws_route53_domain}`
+
____
The base domain of the cluster.
All DNS records will be sub-domains of this base and will also include the cluster name.
____

 ** *Cluster Name*: `disco`
+
____
The name of the cluster.
This will be used when generating sub-domains.
____

 ** *Pull Secret*: Paste the output from minifying this in Step 3.

+
That's it!
The installer will generate `install-config.yaml` and drop it in `/mnt/high-side-data/install` for you.

. We need to make a couple changes to this config before we kick off the install:
 ** Change `publish` from *External* to *Internal*.
We're using private subnets to house the cluster, so it won't be publicly accessible.
 ** Add the subnet IDs for your private subnets to `platform.aws.subnets`.
Otherwise, the installer will create its own VPC and subnets.

Private subnet IDs: `{PrivateSubnets}`

Then add them to `platform.aws.subnets` in your `install-config.yaml` so that they look something like this:

[source,yaml,role=execute,subs="attributes"]
----
...
platform:
  aws:
    region: us-east-1
    subnets:
    - subnet-00f28bbc11d25d523
    - subnet-07b4de5ea3a39c0fd
    - subnet-07b4de5ea3a39c0fd
 ...
----

//  ** Modify the `machineNetwork` to match the IPv4 CIDR blocks from the private subnets.
// Otherwise your control plane and compute nodes will be assigned IP addresses that are out of range and break the install.
// You can retrieve them by running this command from your workstation:
// +
// [source,bash,role=execute,subs="attributes"]
// ----
// aws ec2 describe-subnets | jq '[.Subnets[] | select(.Tags[].Value | contains ("Private")).CidrBlock] | unique | map("cidr: " + .)' | yq read -P - | sed "s/'//g"
// ----
// +
// Then use them to *replace the existing* `networking.machineNetwork` *entry* in your `install-config.yaml` so that they look something like this: ```bash ...
// networking:   clusterNetwork:

//   *** cidr: 10.128.0.0/14 hostPrefix: 23   machineNetwork:
//   *** cidr: 10.0.48.0/20
//   *** cidr: 10.0.64.0/20
//   *** cidr: 10.0.80.0/20 ...

=== Add the `imageContentSources` that `oc mirror` produced to ensure image mappings happen correctly.

*Before continuing*, make sure the second stage of your mirror is done by checking that the `imageContentSourcePolicy.yaml` file exists on disk.

[source,bash,role=execute,subs="attributes"]
----
while true ; do if (test -e /mnt/high-side-data/oc-mirror-workspace/results-*/imageContentSourcePolicy.yaml) ; then break; fi; sleep 5; done
----

Then you can append the relevant snippet to your `install-config.yaml` by running this command:

[source,bash,role=execute]
----
cat <<EOF >> install-config.yaml
imageContentSources:
$(grep "mirrors:" -A 2 --no-group-separator /mnt/high-side-data/oc-mirror-workspace/results-*/imageContentSourcePolicy.yaml)
EOF
----

They'll look something like this:

[source,yaml,role=execute,subs="attributes"]
----
imageContentSources:
  - mirrors:
    - ip-10-0-51-206.ec2.internal:8443/ubi8/ubi
    source: registry.redhat.io/ubi8/ubi
  - mirrors:
     - ip-10-0-51-206.ec2.internal:8443/openshift/release-images
     source: quay.io/openshift-release-dev/ocp-release
  - mirrors:
     - ip-10-0-51-206.ec2.internal:8443/openshift/release
     source: quay.io/openshift-release-dev/ocp-v4.0-art-dev
----

// [NOTE]
// Instead of adding this field to the `install-config.yaml` you could drop the `imageContentSourcePolicy.yaml` file in the manifests directory after running `openshift-install create manifests` to achieve the same result.

** Add the root CA of our mirror registry (`/mnt/high-side-data/quay/quay-install/quay-rootCA/rootCA.pem`) to the trust bundle using the `additionalTrustBundle` field by running this command:

[source,bash,role=execute,subs="attributes"]
----
cat <<EOF >> install-config.yaml
additionalTrustBundle: |
$(sed 's/^/  /' /mnt/high-side-data/quay/quay-install/quay-rootCA/rootCA.pem)
EOF
----

It should look something like this:

[source,yaml,role=execute,subs="attributes"]
----
...
additionalTrustBundle: |
  -----BEGIN CERTIFICATE-----
...
  -----END CERTIFICATE-----
----

. Then make a backup of your `install-config.yaml` since the installer will consume (and delete) it:
[source,bash,role=execute,subs="attributes"]
----
cd /mnt/high-side-data/install
cp install-config.yaml install-config.yaml.backup
----

== Check your work

TODO add complete install-config.yaml

== Running the Installation

We're ready to run the install!
Let's kick off the cluster installation:

[source,bash,role=execute,subs="attributes"]
----
/mnt/high-side-data/openshift-install create cluster --log-level=DEBUG --dir /mnt/high-side-data/install
----

The installation process should take about 30 minutes.
If you've done everything correctly, you should see something like this:

[source,bash,role=execute,subs="attributes"]
----
...
INFO Install complete!
INFO To access the cluster as the system:admin user when using 'oc', run 'export KUBECONFIG=/home/myuser/install_dir/auth/kubeconfig'
INFO Access the OpenShift web-console here: https://console-openshift-console.apps.mycluster.example.com
INFO Login to the console with user: "kubeadmin", and password: "password"
INFO Time elapsed: 30m49s
----
